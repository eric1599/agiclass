Sure, I'll refine the transcription by adding proper punctuation and capitalization, and segment the text into coherent questions and answers.

---

Question: 我们看一下答疑啊，Lowfields是否对代码形容性比较强？

Answer: 你如果用它底层的那个接口，那个不能算侵入吧，因为你得这么理解这个问题。就是说你即使不用它，你在那些关键节点上是不是自己也得打烙的呀？然后你其实本质上是用它这种记录方式代替了你的那个log，对吧？所以呢，你该记录的地方还是得记录的，就是如果你用底层接口的话。所以就是你在代码里本来也应该有这些记录的这个环节。然后你不用底层接口，比如你用回调那种机制，它切入性就没那么强了，你是增加了一个回调而已。

Question: 每个应用包都需要对吗？

Answer: 是的，绝大多数的像什么那个JSON这种是拍摄自带的，但是绝大多数像LAMPTIA、LAMAINDEX这种东西，什么那个PYMUPDF这些东西都是要安装的。

Question: updatecurrenttrace没有这个是不是有没有并发的问题？

Answer: 你问的很好，理论上来讲是有的，因为那是个全局变量，理论上是有的。

Question: 这个教学助手能让我看到完整圆满吗？

Answer: 那个不能啊，不是不给你们看原证原码的原因是啥呢？是那个你们看到这部分就是这个助手最核心的功能了。这个最核心的那个线上的prompt其实就是这版prompt。这个助手核心的不就是prompt吗？它完整的功能里边还涉及跟知乎的那个API打通，然后怎么跟科技二级成，然后就这些东西，包括怎么写那个飞速文档这类的东西。尤其是跟知乎的API打通这个事，它不是对外公开的，这是知乎特意给我们开的，所以这东西不能公开，理解吧？

Question: 用了longserve没有直接掉invoke该怎么回掉？

Answer: 用了longserve其实就是称没有直接调Evoke的话，那个Chain应该也有配置Coback的地方。就是你应该是你定义Chain的时候就应该有一个配Coback的地方。底层接口你查一下我记不住了，但Langston的底层接口肯定是有的。不然你用Langston就不能配Coback，那不就废了吗？这个功能就是整个浪村就废了。所以底层接口是有的，但是我太久不用了，你可以查一下。

Question: 浪field都积下来能不能做向量数据库？

Answer: 能，你如果是需要检索你的对话上下文那种，但这个事要分开啊，这事要分开。这个浪field主要是用于记录的，你可以把记录拉下来然后再处理再去干别的用是可以的，但不要在一个就是他俩，他不是就longfuse本身不是干这功能的，他只是记录数据。至于你拿这个数据记录要干什么是你的事了。

Question: 如果问题里有语境省略或指代inviting效果是不是不好？

Answer: 你说的对，如果有语境的省略指代这类的东西，inviting效果肯定是不好的。但是你用大圆模型那也是个就现在咱们写这个例子，它就是个单轮的。就我们现在的实现就是个单轮的，所以你有语境有指代这种情况下你用哪个方法都不行。我前面用了NLP语音相似度匹配了什么几亿次，大部分还是可以的。

Question: 理论上是否把LongFields记录跟传统的ELK合并在一起？

Answer: 你可以的，那你就自己再做个接口吧，去做合并呗。因为你传动那种日制机制主要是你要寄大模型那些东西，你就传动日制机制还是有一定工作量的。不是不能干，那你大模型返回的投层数啊，寄费啊什么这些你都得自己干嘛。其实反正自己干就有工作量嘛，他longfuse本身就是为了解决你省掉你这个这部分工作量嘛，因为这是个标准问题了，一个JSON就是一个数据集嘛。

Question: LongFields界面是怎么打开的？

Answer: 是在这啊，LongFields那个入口我看看。它是这样的，它的主界面上是它那个入口稍微有点那个不人性。我们看一眼，比如正常你进是这对吧，这是longfields，然后在这在这。如果你没账号这块应该是那个signup注册什么的那种东西。我是已经登录过了，所以点到这直接就进到那个管理后台来了。就是这个界面确实设计的不是太人性。

Question: 支持国产大模型类似Longfield的SDK？

Answer: 你用你用狼琛吧，不行你用Longsmith吧。Longsmith反正至少还能支持他集成过的那些生态的东西，但计费那个事我真没测过啊。我真没测过Longsmith那个，如果你用别的大模型你去计费它好不好使我确实不是很确定。

Question: 实验室代码上没有啊？

Answer: 这个这个猪比特笔记不知识老子第一次追逐记录在网页。昨天本地调了半天啥也没看到数据这么大。正常生产系统是不是把认知传给es或者slunk更合适？你如果真的是特别特别特别海量那种，因为你是用他们那个服务不也收钱吗？你要么私有部署，要么那个你私有部署他后台用的是啥那个那个那个你可以看一眼。我我我我上一期看过的，我给一下蒙住我忘了。就是那个狼fuse的后台存储日志的他用的不是ES就是mongo我如果没记错的话。所以你可以看一眼，如果你真的有很苛刻的需求不行，因为很多东西你给后台给他改了就完了吧。把他把他存储机制给他换一个就完了呗，如果他的不能满足你要求。

Question: 对这俩方法只能用一个？

Answer: 这是前面带A的都是异步的，就是Python的那个写程，然后这个就是统步就串营的。

Question: 实验室直接运行科技二如果能在longfield上看到结果需要什么？

Answer: 你如果运行科技二想看到结果，你去那个啥，你去longfield上自己申请个账号，然后把这个key就环境面量里边这不环境变量里这俩P嘛换成你自己的啊。你就就就能在你自己环境里看到这个结果了，理解吧？就跟就跟哪儿就跟这个地方似的。就跟这个地方似的，把把这个把上边这个环境变量换成你自己的就这个P那俩key我就不一个一个贴了。就把比如把那俩key直接换成你自己的key，然后运行下面代码就可以了。

Question: PromptFlow是那个没删那个什么？

Answer: 我说这个科技的版本好像有点问题吗？我觉得所以这个这个PromptFlow本来已经删了。那个PromptFlow是因为网梯啊，我们讲了微软的SK。虽然PromptFlow跟SK不是严格配套的，但也都是微软生态。那么就连带着介绍了这些SK我们不讲了就PromptFlow也删了。PromptFlow真的不好用，操作起来特别特别晦涩，特别特别特别晦涩，一点都不好用。PromptFlow主要其实它不是作为管理监控用的，它主要更多的是去管理工作流。就有点像LongGraph要干那个事，有点像啊我说。然后那个但是它那个操作包括它那个什么界面设计的非常反人类，就不用不用特别纠结这个事了。

Question: 测试级的回答都是是和否吗？

Answer: 如果是一句话，这不是专门讲了评测指标那个事吗？就是两种，就是一个传统的NLP的评测指标，或者是用大模型来去评估两个句子的相似性。但也不一定是相似性了，就是评估两个句子。你大模型上给你输出的句子和你人工给的标准答案这个句子它俩之间的关系，对吧？你可以评估它俩的相似性，也可以评估说大模型生成的有没有换语言，也可以评估它是不是一个意思。也可以评估说人工给的信息在大模型回复的信息里是不是全部覆盖了。就以这种方式去评估，但是也说了这种评估本身大模型自己也不准，所以得酌情使用。

Question: 快速勾结数据集？

Answer: 你要么就是搁那个底上一条一条标注，确实麻烦。我们在线下做这个事的时候是这么做的。其实有很多开源的数据标注，就传统意义的那个数据标注的工具。你下载一个然后按它指定的格式，因为数据标注这件事对NLP对自然语言处理来说，数据标注这件事无非就几类问题。比如说这种打标签的是一类，对两个句子去做比较的这是一类。然后在一个句子上面去抽取信息的，就所谓的命运实体识别。比如说把地址给划出来，把那个什么人比人给划出来，这是一大类。反正无非就是自然语言处理去设计的标注一共也就那么几种类型。然后有那种开源的数据标注的工具，你搜一下就行，有很多也没什么可推荐的都差不多。你去找一个然后把你的数据处理成他那种格式，然后用那种他那种工具主要为了都是你操作便利。就可以点点鼠标就一个点点鼠标就一个，就是这种方式。所以这样的话会快一点。

Question: 今天来讲我想比较几个大模型的准确性有没有什么好的方法和工具？

Answer: 这不是有公开评测吗？大模型不是有那个公开评测吗？那个榜单叫什么来着？最近脑子真的有点有点什么，这都是刷大模型刷大模型的那个就是怎么说那个那个好坏的那个榜。尤其是什么这些玩意儿这些玩意儿你想评测大模型的话你就可以去刷这些榜。然后这些榜里边它有多个维度的指标，比如跟推理相关的，跟数学计算相关的，跟那个什么阅读理解相关的，跟什么那个什么分类相关的等等。然后你可以根据你自己的使用情况，你看哪个指标跟你想解决的问题更贴切，从这个维度来观察吧。

Question: 本地的浪費用途是這樣的？

Answer: 就是以那個什麼剛才其實講過了。就再跟你說一下我們剛才本地那個这是我们本地部的对吧？这是我们本地部的，然后呢你想去创建那个API呢就在这在Sightings就在你上你自己本地部那个服务里边。然后在Sightings里边啊去创建你自己的key啊去创建你自己的key明白吧？我没权限啊，因为这这是那个HCIclass那个网管创建的。我有权限我能创建啊，你就在这创建一个key就完了。然后你连的时候这个就是你自己本地服务那个地址往UIP也行，就你没有域名的UIP也行。然后这不课上前面不是讲了吗？本地服务的话你配的时候就是你如果云端服务你就配这两个key。如果是本地服务你就需要配三个东西，除了那两个key之外还有一个你的那个地址是啥。然后就连到你自己本地服务上看看啥有啥问题。

Question: 今天选出来的问题有点少诶，知识库的概念是指存文档的软件还是本地一个文件夹就可以代替了？

Answer: 知识库知识库不是个技术名词。知识库就是你有一大堆知识，然后你这个库到底是个啥类型的库这件事完全根据你应用定的。你的你存的也可能是个sql也可能是项量数据库对吧？也也可能是个图数据库是完全根据你知识是咋整理的和你咋用定的。所以知识库其实是个是个科普概念，知识库不是个严谨的科学概念。

Question: 大明师傅可以做出工业控制中温度控制的PID？

Answer: 这个够呛够呛。

Question: 有类似国产产品？

Answer: 我还真没看到有人又知道有类似的国产产品吗？国人在这方面工具软件上不是特别不是不是特别怎么说呢擅长吧。就不是说水平上擅长就是整个生态各方面可能都不是特别擅长。水平上到这东西没啥东西。

Question: Longfuse应该不需要啊？

Answer: Longfuse应该不需要，而且Longfuse不是可以本地部署吗？

Question: 想做一个本地大模型用来回答维修问题用哪个大模型好？

Answer: 你就是其实如果你是个REG这类的现在都你说本地大模型啊本地的话你试试千万二吧。千万二在这方面能力还可以啊你可以试试。

Question: 有没有开源的文本数据清洗工具框架吗？

Answer: 数据清洗这个事是跟业务强相关的。你到底要洗啥这些事我们在微调那堂课会专门讲说数据的准备和清洗，然后从哪些维度考虑怎么洗这些东西。但问题是这东西跟你实际的具体的问题强相关，它不是个通用的东西。所以那咋框架啊？这东西就应该自己写代码最最最贴你自己的需求。

Question: 大模型项目是不是也是LamaIndex和LongChain协调的一起用？

Answer: LongFuse也用是不是本地都是大模型外挂知识库这种类型。我做过的就不止这些，但这些是市面上最常见的。你们能想出来的跟文文打交道的事儿除了医疗和教育应该没有我没做过的。

Question: 传统设备检测系统通过大观星人生成一个检修专题工作报告这个报告数据我们描述有表表是你生成表还是你解读表？

Answer: 你要生成表你就生成代码生成图表表还好说生成图你就生成代码然后用代码画图。你要是解读表这个事看你要能用国外那几个比较好的多模态还行。你要用不了这事有点费劲开源的啥的不太够。

Question: 拉马cpp是个部署是个部署框架它不是大模型本身？

Answer: 刚才1.3粒子里边开始纯的是啥是吧？1.3里边开始纯的是embedding这个例子哪去了？这开始纯的是个embedding是啥意思？你看我不是去取embedding你输入一个文本我要去取它的项料取它的项量的时候。如果我发现它已经在缓存里了已经在缓存里了我就不需要再调一遍OpenAI了。因为调OpenAI既费时间也费token。所以我就如果它已经在缓存里了我就直接从缓存里取。如果它没在缓存里的话我就调一遍OpenAI的接口拿到一个项量。然后再把这个项量就是文本当key,然后项链当value放进catch里。就为了这个同样的你多次调用多次取项链不需要重复的去访问OpenAI干了这么个事。其实这种东西在线上你也该这么做但不是这么简单啊。不是你在代码里写个开始就完了。就是你在线上的话其实你可以通过Redis什么这类的机制去建这么一个开始的机制。也就是说你如果只是单纯对于取项量这个操作你频繁进行的时候你是可以把这个已经取过的就存下来的不需要反复去取的。这样你可以省token也省时间这个目前他没给你提供自动的。你调底层接口能手工删你可以去自己去那个啥。你自己去定一个比如你存多久然后就删了然后手工去周期性执行那个东西就行了。

Question: 有没有可能保单跑出高分的模型？

Answer: 太有可能了呀太有可能了呀。

Question: 大模型准学率和大模型有关还是跟序列有关？

Answer: 主要跟序列有关，因为大模型里边那个结构都大差不差都大差不差。主要跟序列数据有关还跟其实跟很多因素有关。它真的那种像GPD4那么大的模型它上线部署了之后是个很复杂的架构。至少它是个MOE它前面还做了一大堆很dirty的那个trick在前面。跟这些所有因素都有关。你像那个GPD4这种东西它为了快它其实你的query号我印象中有一篇文章给它详细分析过。他应该是先有个小模型去做了个预判然后预判完了之后他是有多少是不掉大模型的有多少是掉大模型的。反正就是他做了很复杂的一套工作。那你要端来端去看准确率的话跟这些所有的每个环节都有关。但最核心的咱们说那个最核心的跟啥有关跟他训练数据有关。

Question: 公开的测试集可以从哪下载？

Answer: 那个hackingface上有大量的公开的那种benchmark的数据集。这个咱们模型训练那堂课也会讲。你要是着急你就去搜一下hackingface这上面有大量的开源模型大量的这个数据集大量的那个什么评测标准。你看这就是数据集然后各种各样的你就在那边搜就行了。然后现在基本上它变成了一个这个NLP或者说大模型领域的一个一个什么一个GitHub了。所以就很多学术研究说他自己去构建了一个数据集然后