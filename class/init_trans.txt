我们看一下答疑啊Lowfields是否对代码形容性比较强你如果用它底层的那个接口那个不能算侵入吧因为你得这么理解这个问题就是说你即使不用它你在那些关键节点上是不是自己也得打烙的呀然后你其实本质上是用它这种记录方式代替了你的那个log对吧所以呢你该记录的地方还是得记录的就是如果你用底层接口的话所以就是你在代码里本来也应该有这些记录的这个环节然后你不用底层接口比如你用回掉那种机制它切入性就没那么强了你是增加了一个回掉而已每个应用包都需要对是的就绝大多数的像什么那个JSON这种是拍摄自带的但是绝大多数像LAMPTIA什么LAMAINDEX就这种东西什么那个PYMUPDF什么这些东西都是要安装的updatecurrenttrace没有这个不是是不是有没有并发的问题你问的很好理论上来讲是有的因为那是个全局变量那是个全局变量理论上是有的这个教学助手能让我看到完整圆满吗那个不能啊不是不给你们看原证原码的原因是啥呢是那个你们看到这部分就是这个助手最核心的功能了这个最核心的那个线上的prompt其实就是这版prompt这个助手核心的不就是prompt吗它完整的功能里边还涉及跟知乎的那个API打通然后怎么跟科技二级成然后就这些东西包括怎么写那个飞速文档这类的东西尤其是跟知乎的API打通这个事它不是对外公开的这是知乎特意给我们开的所以这东西不能公开理解吧用了longserve没有直接掉invoke该怎么回掉用了longserve其实就是称没有直接调Evoke的话那个Chain应该也有配置Coback的地方就是你应该是你定义Chain的时候就应该有一个配Coback的地方底层接口你查一下我记不住了但Langston的底层接口肯定是有的不然你的你用Langston就不能配Coback那不就废了吗这个功能就是整个浪村就废了所以底层接口是有的但是我太久不用了你可以查一下浪field都积下来能不能做向量数据库能你如果是需要检索检索你的对话上下文那种但这个事要分开啊这事要分开这个浪field主要是用于记录的你可以把记录拉下来然后再处理再去干别的用是可以的但不要在一个就是他俩他不是就longfuse本身不是干这功能的他只是记录数据至于你拿这个数据记录要干什么是你的事了好吧如果问题里有语境省略或指代inviting效果是不是不好你说的对如果有语境的省略指代这类的东西inviting效果肯定是不好的但是你用大圆模型那也是个就现在咱们写这个例子它就是个单轮的就我们现在的实现就是个单轮的所以你有语境有指代这种情况下你用哪个方法都不行我前面用了NLP语音相似度匹配了什么几亿次大部分还是可以的不知道说的是啥事但应该还行你还是牛两下子理论上是否把LongFields记录跟传统的ELK合并在一起你可以的那你就自己再做个接口吧去做合并呗因为你传动那种日制机制主要是你要寄大模型那些东西你就传动日制机制还是有一定工作量的不是不能干那你大模型返回的投层数啊寄费啊什么这些你都得自己干嘛其实反正自己干就有工作量嘛他longfuse本身就是为了解决你省掉你这个这部分工作量嘛因为这是个标准问题了一个JSON就是一个数据集嘛这个问题还有点诡异那个不是是我们把那个JSON我们把数据集存成了一个JSON格式一条记录一个JSONJSON是个数据格式有一些基础概念我们就没法在这展那么细了LongFields界面是怎么打开的是在这啊LongFields那个入口我看看它是这样的它的主界面上是它那个入口稍微有点那个不人性我们看一眼比如正常你进是这对吧这是longfields然后在这在这如果你没账号这块应该是那个signup注册什么的那种东西我是已经登录过了所以点到这直接就进到那个管理后台来了就是这个界面确实设计的不是太人性支持国产大模型类似Longfield的SDK你用你用狼琛吧不行你用Longsmith吧Longsmith反正至少还能支持他集成过的那些生态的东西但计费那个事我真没测过啊我真没测过Longsmith那个如果你用如果你用别的大模型你去计费它好不好使我确实不是很确定实验室代码上没有啊这个这个猪比特笔记不知识老子第一次追逐记录在网页昨天本地调了半天啥也没看到数据这么大正常生产系统是不是把认知传给es或者slunk更合适你如果真的是特别特别特别海量那种因为你是用他们那个服务不也收钱吗你要么私有部署要么那个你私有部署他后台用的是啥那个那个那个你可以看一眼我我我我上一期看过的我给一下蒙住我忘了就是那个狼fuse的后台存储日志的他用的不是ES就是mongo我如果没记错的话所以你可以看一眼如果你真的有很苛刻的需求不行因为很多东西你给后台给他改了就完了吧把他把他存储机制给他换一个就完了呗如果他的不能满足你要求对这俩方法只能用一个这是前面带A的都是异步的就是Python的那个写程然后这个就是统步就串营的实验室直接运行科技二如果能在longfield上看到结果需要什么你如果运行科技二想看到结果你去那个啥你去longfield上自己申请个账号然后把这个key就环境面量里边这不环境变量里这俩P嘛换成你自己的啊你就就就能在你自己环境里看到这个结果了理解吧就跟就跟哪儿就跟这个地方似的就跟这个地方似的把把这个把上边这个环境变量换成你自己的就这个P那俩key我就不一个一个贴了就把比如把那俩key直接换成你自己的key然后运行下面代码就可以了PromptFlow是那个没删那个什么我说这个科技的版本好像有点问题吗我觉得所以这个这个PromptFlow本来已经删了那个PromptFlow是因为网梯啊我们讲了微软的SK虽然PromptFlow跟SK不是严格配套的但也都是微软生态那么就连带着介绍了这些SK我们不讲了就PromptFlow也删了PromptFlow真的不好用操作起来特别特别晦涩特别特别特别晦涩一点都不好用PromptFlow主要其实它不是作为管理监控用的它主要更多的是去管理工作流就有点像LongGraph要干那个事有点像啊我说然后那个但是它那个操作包括它那个什么界面设计的非常反人类就不用不用特别纠结这个事了测试级的回答都是是和否吗如果是一句话这不是专门讲了评测指标那个事吗就是两种就是一个传统的NLP的评测指标或者是用大模型来去评估两个句子的相似性但也不一定是相似性了就是评估两个句子你大模型上给你输出的句子和你人工给的标准答案这个句子它俩之间的关系对吧你可以评估它俩的相似性也可以评估说大模型生成的有没有换语言也可以评估它是不是一个意思也可以评估说人工给的信息在大模型回复的信息里是不是全部覆盖了就以这种方式去评估但是也说了这种评估本身大模型自己也不准所以得酌情使用快速勾结数据集你要么就是搁那个底上一条一条标注确实麻烦我们在线下做这个事的时候是这么做的其实有很多开源的数据标注就传统意义的那个数据标注的工具你下载一个然后按它指定的格式因为数据标注这件事对NLP对自然语言处理来说数据标注这件事无非就几类问题比如说这种打标签的是一类对两个句子去做比较的这是一类然后在一个句子上面去抽取信息的就所谓的命运实体识别比如说把地址给划出来把那个什么人比人给划出来这是一大类反正无非就是自然语言处理去设计的标注一共也就那么几种类型然后有那种开源的数据标注的工具你搜一下就行有很多也没什么可推荐的都差不多你去找一个然后把你的数据处理成他那种格式然后用那种他那种工具主要为了都是你操作便利就可以点点鼠标就一个点点鼠标就一个就是这种方式所以这样的话会快一点今天来讲我想比较几个大模型的准确性有没有什么好的方法和工具这不是有公开评测吗大模型不是有那个公开评测吗那个榜单叫什么来着最近脑子真的有点有点什么这都是刷大模型刷大模型的那个就是怎么说那个那个好坏的那个榜尤其是什么这这些玩意儿这些玩意儿你想评测大模型的话你就可以去刷这些榜然后这些榜里边它有多个维度的指标比如跟推理相关的跟数学计算相关的跟那个什么阅读理解相关的跟什么那个什么分类相关的等等然后你可以根据你自己的使用情况你看哪个指标跟你想解决的问题更贴切从这个维度来观察吧本地的浪費用途是這樣的就是以那個什麼剛才其實講過了就再跟你說一下我們剛才本地那個这是我们本地部的对吧这是我们本地部的然后呢你想去创建那个API呢就在这在Sightings就在你上你自己本地部那个服务里边然后在Sightings里边啊去创建你自己的key啊去创建你自己的key明白吧我没权限啊因为这这是那个HCIclass那个网管创建的我有权限我能创建啊你就在这创建一个key就完了然后你连的时候这个就是你自己本地服务那个地址往UIP也行就你没有域名的UIP也行然后这不课上前面不是讲了吗本地服务的话你配的时候就是你如果云端服务你就配这两个key如果是本地服务你就需要配三个东西除了那两个key之外还有一个你的那个地址是啥然后就连到你自己本地服务上看看啥有啥问题今天选出来的问题有点少诶知识库的概念是指存文档的软件还是本地一个文件夹就可以代替了知识库知识库不是个技术名词知识库就是你有一大堆知识然后你这个库到底是个啥类型的库这件事完全根据你应用定的你的你存的也可能是个sql也可能是项量数据库对吧也也可能是个图数据库是完全根据你知识是咋整理的和你咋用定的所以知识库其实是个是个科普概念知识库不是个严谨的科学概念大明师傅可以做出工业控制中温度控制的PID这个够呛够呛有类似国产产品我还真没看到有人又知道有类似的国产产品吗国人在这方面工具软件上不是特别不是不是特别怎么说呢擅长吧就不是说水平上擅长就是整个生态各方面可能都不是特别擅长水平上到这东西没啥东西Longfuse应该不需要啊Longfuse应该不需要而且Longfuse不是可以本地部署吗想做一个本地大模型用来回答维修问题用哪个大模型好都你就是其实如果你是个REG这类的现在都你说本地大模型啊本地的话你试试千万二吧千万二在这方面能力还可以啊你可以试试有没有开源的文本数据清洗工具框架吗数据清洗这个事是跟业务强相关的你到底要洗啥这些事我们在微调那堂课会专门讲说数据的准备和清洗然后从哪些维度考虑怎么洗这些东西但问题是这东西跟你实际的具体的问题强相关它不是个通用的东西所以那咋框架啊这东西就应该自己写代码最最最贴你自己的需求大模型项目是不是也是LamaIndex和LongChain协调的一起用LongFuse也用是不是本地都是大模型外挂知识库这种类型我做过的就不止这些但这些是市面上最常见的你们能想出来的跟文文打交道的事儿除了医疗和教育应该没有我没做过的传统设备检测系统通过大观星人生成一个检修专题工作报告这个报告数据我们描述有表表是你生成表还是你解读表你要生成表你就生成代码生成图表表还好说生成图你就生成代码然后用代码画图你要是解读表这个事看你要能用国外那几个比较好的多模态还行你要用不了这事有点费劲开源的啥的不太够拉马cpp是个部署是个部署框架它不是大模型本身刚才1.3粒子里边开始纯的是啥是吧1.3里边开始纯的是embedding这个例子哪去了这开始纯的是个embedding是啥意思你看我不是去取embedding你输入一个文本我要去取它的项料取它的项量的时候如果我发现它已经在缓存里了已经在缓存里了我就不需要再调一遍OpenAI了因为调OpenAI既费时间也费token所以我就如果它已经在缓存里了我就直接从缓存里取如果它没在缓存里的话我就调一遍OpenAI的接口拿到一个项量然后再把这个项量就是文本当key,然后项链当value放进catch里,就为了这个同样的你多次调用多次取项链不需要重复的去访问OpenAI干了这么个事其实这种东西在线上你也该这么做但不是这么简单啊不是你在代码里写个开始就完了就是你在线上的话其实你可以通过Redis什么这类的机制去建这么一个开始的机制也就是说你如果只是单纯对于取项量这个操作你频繁进行的时候你是可以把这个已经取过的就存下来的不需要反复去取的这样你可以省token也省时间这个目前他没给你提供自动的你调底层接口能手工删你可以去自己去那个啥你自己去定一个比如你存多久然后就删了然后手工去周期性执行那个东西就行了有没有可能保单跑出高分的模型太有可能了呀太有可能了呀大模型准学率和大模型有关还是跟序列有关主要跟序列有关因为大模型里边那个结构都大差不差都大差不差主要跟序列数据有关还跟其实跟很多因素有关它真的那种像GPD4那么大的模型它上线部署了之后是个很复杂的架构至少它是个MOE它前面还做了一大堆很dirty的那个trick在前面跟这些所有因素都有关你像那个GPD4这种东西它为了快它其实你的query号我印象中有一篇文章给它详细分析过他应该是先有个小模型去做了个预判然后预判完了之后他是有多少是不掉大模型的有多少是掉大模型的反正就是他做了很复杂的一套工作那你要端来端去看准确率的话跟这些所有的每个环节都有关但最核心的咱们说那个最核心的跟啥有关跟他训练数据有关公开的测试集可以从哪下载那个hackingface上有大量的公开的那种benchmark的数据集这个咱们模型训练那堂课也会讲你要是着急你就去搜一下hackingface这上面有大量的开源模型大量的这个数据集大量的那个什么评测标准你看这就是数据集然后各种各样的你就在那边搜就行了然后现在基本上它变成了一个这个NLP或者说大模型领域的一个一个什么一个GitHub了所以就很多学术研究说他自己去构建了一个数据集然后他也会在这上面发布比如志愿研究院这发布的这是个啥数据集你自己去看看这就是咱们北京志愿研究院发布的对吧你就可以在上面去找做REG多轮对话的时候REGfusion是要判断芯体的问题和上下纹不相关嘛一般怎么做你可以做一个那个啥你可以做一个分类器用prompt做一个分类器分类器是两种做法一种做法是你直接带着上下纹然后就告诉他说如果他有这种剧毒成分缺失就根据上下纹自动去补充如果没有就是原始问题这是一种做法另一种这种做法就是这种做法的缺点是不好调然后因为你整个带着上下纹上下纹一变它就会变这个不好调你要是想精准可调的话就是把这个问题单拎出来拿那个query先做个分类器就是一个prompt去做分类器就分一轮的就分query本身然后就判断这个query有没有句子成分缺失就是成分缺失在语言学上有几种反正就是主语省略什么必语省略然后也有动词省略的反正有几种情况看你的场景要不要分那么细然后如果判断有句子成分缺失或者是有代词或者代词就是那个anaphyral这种东西然后代词里边还有那种就是主语学识其实是zeroanaphyral一种特殊现象反正就是你判断这种语言学现象判断如果出现的话你就用上下文对它做补全如果没出现这种语言现象它就是一个完整的query就这么个逻辑就这么个逻辑就那你细抠还得测啊得听听听听就也没啥好办法就是个挺细的活儿那个低飞有没有学习价值低飞没啥可学习的那东西太易用了你拿来用就行了有啥学习价值啊你拿你只是拿它能直接上线吗但是他特别方便的是说你想你有个idea我快速的搭一个流程就验证一下他是干这个用的目前来看的话我是不建议你拿那种就是底层全是黑盒子的就一个特别简单的就近乎于无代码的情况然后你就上线了到底有啥坑你也不知道,你要真的是严谨的一个服务的话,最好是自己写代码,但是那个Diffie那种东西就特别特别适合你有个idea,我还就写代码总会要花时间的嘛,我就快速的吧一验证就完事主要声称专题报告内容像大模型除大纲,functioncalling声称图表不太有控制那个地方最好有一个专门的模块我的建议你要是不擅长这个你就用functioncalling也行但是方程考虑最大的问题就是尤其在这种模糊的场景到底要不要靠不是特别好控制所以我建议你是先生成大纲然后有一个专门的模块比如说你先生成这一段这一个section的内容生成完了之后你有一个专门模块说这个section里哪个地方需不需要配图然后如果他判断需要配图你就在那个位置再去插图然后那个图再用代码生成它其实本质上是个工作流但是它有点像多智能体写作的这种场景然后也看你那个报告本身要写到多细的力度你甚至写的时候它不是大纲完了就直接一段一段写如果你要写特别详细的话其实你大纲完了之后每个chapter要分section甚至要分paragraph的所谓的故事线然后才到这种力度之后让每一个故事线每一个故事线然后带着沙夏文去生成这样可控的程度最高这是我们已经实践上验证过的就看你那个要求有多高了大刚基于检修系统的所有数据给出最好这种东西你对那个数据我总结你要是全是裸的数据就一堆树丢给大模型上这个事不是特别anyway你这项目太细了就是你就是一堆树丢给大模型大模型在这方面的能力其实比较有限尤其是有的时候真的不行你这事太细了咱就不在课上就都这么细的掰扯了好吧那个咱们有项目拆解课听上去你这个是个你真的要做的而且已经在可能在动手了你把这个到时候项目拆解课的时候把这你的整个需求详细描述一下我跟你连麦来去讨论可能更更有帮助一些大模型面向供应链业务供应链里你这么考虑吧供应链里哪个环节需要AI我是没有特别可能这个领域我不是那么熟啊你想想哪个领域需要AI吧咱们再讨论就是供应链里到底有啥问题需要解决这个这个如果是路径规划这事不是大模型本身的事运车学的事啊只要不是路径规划的咱们那个就是比如文本分析啊什么这个图像分析啊这类的事咱们再讨论行时间也差不多了我看也没啥问题了旅游路线这种是可以用大模型的旅游路线但这不是大模型自己就能解决了你还是得还是你的数据资源和大模型结合着来用它是个综合的东西了不是一个端到端就搞定的事大模型面向建筑设计三维史量模型三维模型的生成目前不是特别成熟但是有望在近期成熟但生成的都是blob就是那个就是三维的那个叫什么点云你建筑模型本身我理解就是要么是cd要么是b目里边也除了设计图纸还有信息所以直接用大模型生成这件事是肯定是目前不够成熟的但是对你有假设说你是并不长期有用大模型在里边做分析这件事还是有很多价值可以挖掘的WZQQ你是啥问题我看你说的对每个人对话互不影响使用自己的定义的角色对话删下文能同时给多个人使用你说的对啊就分给他隔离就完了呀用userID把他的对话删下文隔离就完了本地做REG看你能允许多大的啊看你能允许多大的我个人建议就是大的肯定会比小的好啊实际你没法定说哪个你测吧又看你是啥问题因为你他跟领域不一样哪个能用能源能力也不一样但是头部那几个应该差不多太多你可以先试试然后如果你的模型比如说6B7B这种模型在你那个专业领域里他不是特别好用的话你可以换个大点的就是这种你想效果有保证都建议我建议啊就是如果是纯本地只是做REG啊不是做特别复杂就是做REG我建议十几B以上的啊如果有70B的能跑起来更好尤其像那个千万二72B真的效果还不错啊效果还是真的不错的你可以试试啊AIGC生成点云这事目前不是特别成熟但是有成熟的趋势了今年陆陆续续的看到点这种就是那些大型研究机构发的不管是demo也好还是什么也好所以咱们拭目以待吧这东西咋弄其实如果做推理的话没有几块如果你只做推理的话看你多少并发吧看你要峰值要能要能享用多少并发四块八块应该差不多如果只做推理的话量化到那个斯比特那种那种那种情况只做推理训练不行训练就比较吃钻力行吧咱们咱们今天到这行不行咱们现在下周下周咱们手撸一个整体好吧下了下了拜拜了啊